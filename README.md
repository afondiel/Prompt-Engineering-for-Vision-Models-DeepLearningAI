# Prompt Engineering for Vision Models Crash Course - Notes

## Overview

These notes and resources are compiled from the crash course [Prompt Engineering for Vision Models](https://learn.deeplearning.ai/courses/prompt-engineering-for-vision-models/lesson/1/introduction) like [Meta's SAM (Segment Anything Model)](https://segment-anything.com/) or [Stable Diffusion](https://huggingface.co/stabilityai/stable-diffusion-3-medium), offered by [DeepLearning.AI](https://www.deeplearning.ai/).

The course, led by `Andrew Ng` and instructors from [Comet](https://www.comet.com/site/) (**Abby Morgan, Jacques Verr√©, and Caleb Kaiser**), explores techniques for prompting vision models like image generation and object detection.

## Key Concepts:

- Gain a foundational understanding of prompt engineering techniques for guiding vision models.
- Explore methods for image generation, object detection, and image segmentation using text prompts.
- Learn to fine-tune diffusion models for personalized image creation with DreamBooth.
- Discover best practices for experimenting and tracking progress in prompt engineering workflows.

## Course Contents

- [Lesson0: Introduction](#)
- [Lesson1: Overview](#)
- [Lesson2: Image Segmentation](#)
- [Lesson3: Object Detection](#)
- [Lesson4: Image Generation](#)
- [Lesson5: Fine-tuning](#)
- [Lesson6: Conclusion](#)


## References

Main Course : 
- https://learn.deeplearning.ai/courses/prompt-engineering-for-vision-models/lesson/1/introduction

Others short Free Courses available on DeepLearning.AI : 
- https://learn.deeplearning.ai/





